{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6347995",
   "metadata": {},
   "source": [
    "# Spaceship Titanic Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d75dd1",
   "metadata": {},
   "source": [
    "### Goals: do some fine tuning with the model, features, etc using st_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d2b48",
   "metadata": {},
   "source": [
    "To Do List - check if model can absorb nulls, if not convert floats to int (can't do that until there are no nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e4f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003b7c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e2a53",
   "metadata": {},
   "source": [
    "setting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a35ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cabin = train_data['Cabin'].str.split('/', 3, expand=True)\n",
    "cabin.columns = ['Deck', 'Num', 'Side']\n",
    "train_data_mod = pd.concat([train_data, cabin], axis=1)\n",
    "train_data_mod.drop(['Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd75487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'HomePlanet',\n",
       " 'CryoSleep',\n",
       " 'Destination',\n",
       " 'Age',\n",
       " 'VIP',\n",
       " 'RoomService',\n",
       " 'FoodCourt',\n",
       " 'ShoppingMall',\n",
       " 'Spa',\n",
       " 'VRDeck',\n",
       " 'Name',\n",
       " 'Deck',\n",
       " 'Num',\n",
       " 'Side']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train_data_mod.columns.drop('Transported').to_list()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80dbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_data_mod[features]\n",
    "y = train_data_mod.Transported\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78b227",
   "metadata": {},
   "source": [
    "list of all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163e1dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'HomePlanet',\n",
       " 'CryoSleep',\n",
       " 'Destination',\n",
       " 'VIP',\n",
       " 'Name',\n",
       " 'Deck',\n",
       " 'Num',\n",
       " 'Side']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = X_train.select_dtypes(include='object').columns.to_list()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3fef0",
   "metadata": {},
   "source": [
    "(code from the kaggle tutorial - checking to see how many unique values are in each categorical column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d666443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CryoSleep', 2),\n",
       " ('VIP', 2),\n",
       " ('Side', 2),\n",
       " ('HomePlanet', 3),\n",
       " ('Destination', 3),\n",
       " ('Deck', 8),\n",
       " ('Num', 1712),\n",
       " ('Name', 6350),\n",
       " ('PassengerId', 6519)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), cat_cols))\n",
    "d = dict(zip(cat_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b84fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecat = ['CryoSleep', 'HomePlanet', 'Destination', 'Deck', 'Side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c91c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592583a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6519 entries, 0 to 6518\n",
      "Data columns (total 23 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6519 non-null   float64\n",
      " 1   1       6519 non-null   float64\n",
      " 2   2       6519 non-null   float64\n",
      " 3   3       6519 non-null   float64\n",
      " 4   4       6519 non-null   float64\n",
      " 5   5       6519 non-null   float64\n",
      " 6   6       6519 non-null   float64\n",
      " 7   7       6519 non-null   float64\n",
      " 8   8       6519 non-null   float64\n",
      " 9   9       6519 non-null   float64\n",
      " 10  10      6519 non-null   float64\n",
      " 11  11      6519 non-null   float64\n",
      " 12  12      6519 non-null   float64\n",
      " 13  13      6519 non-null   float64\n",
      " 14  14      6519 non-null   float64\n",
      " 15  15      6519 non-null   float64\n",
      " 16  16      6519 non-null   float64\n",
      " 17  17      6519 non-null   float64\n",
      " 18  18      6519 non-null   float64\n",
      " 19  19      6519 non-null   float64\n",
      " 20  20      6519 non-null   float64\n",
      " 21  21      6519 non-null   float64\n",
      " 22  22      6519 non-null   float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe_train = pd.DataFrame(ohe.fit_transform(X_train[usecat]))\n",
    "ohe_valid = pd.DataFrame(ohe.transform(X_valid[usecat]))\n",
    "\n",
    "ohe_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7405cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding removed index; put it back\n",
    "ohe_train.index = X_train.index\n",
    "ohe_valid.index = X_valid.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd4f1e",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfc6d7",
   "metadata": {},
   "source": [
    "setting up for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3889306e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = train_data._get_numeric_data()\n",
    "num.drop(['Transported'], axis=1, inplace=True)\n",
    "numdata = num.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe895",
   "metadata": {},
   "source": [
    "slightly modified code from the kaggle tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a076f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870ccd5",
   "metadata": {},
   "source": [
    "(I'm just splitting up a cell here so I can see what is taking so long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e94ee3",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/67361786/how-to-measure-random-forest-classifier-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6cd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f5114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6519 entries, 4451 to 1995\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Age           6519 non-null   float64\n",
      " 1   RoomService   6519 non-null   float64\n",
      " 2   FoodCourt     6519 non-null   float64\n",
      " 3   ShoppingMall  6519 non-null   float64\n",
      " 4   Spa           6519 non-null   float64\n",
      " 5   VRDeck        6519 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 356.5 KB\n"
     ]
    }
   ],
   "source": [
    "i = SimpleImputer(strategy='most_frequent')\n",
    "i_X_train = pd.DataFrame(i.fit_transform(X_train[numdata]))\n",
    "i_X_valid = pd.DataFrame(i.transform(X_valid[numdata]))\n",
    "\n",
    "i_X_train.columns = X_train[numdata].columns\n",
    "i_X_valid.columns = X_valid[numdata].columns\n",
    "\n",
    "i_X_train.index = X_train.index\n",
    "i_X_valid.index = X_valid.index\n",
    "\n",
    "i_X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392afc0b",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6debbe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6519 entries, 4451 to 1995\n",
      "Data columns (total 29 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Age           6519 non-null   float64\n",
      " 1   RoomService   6519 non-null   float64\n",
      " 2   FoodCourt     6519 non-null   float64\n",
      " 3   ShoppingMall  6519 non-null   float64\n",
      " 4   Spa           6519 non-null   float64\n",
      " 5   VRDeck        6519 non-null   float64\n",
      " 6   0             6519 non-null   float64\n",
      " 7   1             6519 non-null   float64\n",
      " 8   2             6519 non-null   float64\n",
      " 9   3             6519 non-null   float64\n",
      " 10  4             6519 non-null   float64\n",
      " 11  5             6519 non-null   float64\n",
      " 12  6             6519 non-null   float64\n",
      " 13  7             6519 non-null   float64\n",
      " 14  8             6519 non-null   float64\n",
      " 15  9             6519 non-null   float64\n",
      " 16  10            6519 non-null   float64\n",
      " 17  11            6519 non-null   float64\n",
      " 18  12            6519 non-null   float64\n",
      " 19  13            6519 non-null   float64\n",
      " 20  14            6519 non-null   float64\n",
      " 21  15            6519 non-null   float64\n",
      " 22  16            6519 non-null   float64\n",
      " 23  17            6519 non-null   float64\n",
      " 24  18            6519 non-null   float64\n",
      " 25  19            6519 non-null   float64\n",
      " 26  20            6519 non-null   float64\n",
      " 27  21            6519 non-null   float64\n",
      " 28  22            6519 non-null   float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Add one-hot encoded columns to numerical features\n",
    "both_X_train = pd.concat([i_X_train, ohe_train], axis=1)\n",
    "both_X_valid = pd.concat([i_X_valid, ohe_valid], axis=1)\n",
    "both_X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f11573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_X_train.columns = both_X_train.columns.astype(str)\n",
    "both_X_valid.columns = both_X_valid.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3865402",
   "metadata": {},
   "source": [
    "importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b001f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1ae7a",
   "metadata": {},
   "source": [
    "doing some loops to see which parameters are the best for the gradient boosting, the lists changed to various tings throughout the process as I ran the loop and did some tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5afad",
   "metadata": {},
   "source": [
    "https://intellipaat.com/blog/gradient-boosting-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4806f20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features:  100\n",
      "Accuracy: 0.8077276908923643\n",
      "max_features:  125\n",
      "Accuracy: 0.8058877644894205\n",
      "max_features:  150\n",
      "Accuracy: 0.8077276908923643\n",
      "max_features:  175\n",
      "Accuracy: 0.8054277828886844\n",
      "max_features:  250\n",
      "Accuracy: 0.8058877644894205\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 125, 150, 175, 250]\n",
    "max_features = [1, 2, 5, 8]\n",
    "max_depth = [1, 2, 3, 4, 5]\n",
    "\n",
    "for n in n_estimators:\n",
    "    model = GradientBoostingClassifier(n_estimators=n, max_features=8, max_depth=5, random_state=1)\n",
    "    model.fit(both_X_train, y_train)\n",
    "    preds = model.predict(both_X_valid)\n",
    "    print(\"max_features: \", n)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e696409",
   "metadata": {},
   "source": [
    "the model with the highest accuracy score shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "061acf83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  250\n",
      "max_features:  10\n",
      "Accuracy: 0.7907083716651334\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=150, max_features=5, max_depth=2, random_state=1)\n",
    "model.fit(both_X_train, y_train)\n",
    "preds = model.predict(both_X_valid)\n",
    "print(\"n_estimators: \", n)\n",
    "print(\"max_features: \", f)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa189cb4",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3659b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features=8, n_estimators=150,\n",
       "                           random_state=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing what I did to my data to all my training data\n",
    "ohe_X = pd.DataFrame(ohe.transform(X[usecat]))\n",
    "ohe_X.index = X.index\n",
    "\n",
    "i_X = pd.DataFrame(i.transform(X[numdata]))\n",
    "i_X.columns = X[numdata].columns\n",
    "i_X.index = X.index\n",
    "\n",
    "both_X = pd.concat([i_X, ohe_X], axis=1)\n",
    "both_X.columns = both_X.columns.astype(str)\n",
    "\n",
    "# i_X.info()\n",
    "\n",
    "model.fit(both_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80296440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jeron Peter</td>\n",
       "      <td>G</td>\n",
       "      <td>1496</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Matty Scheron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jayrin Pore</td>\n",
       "      <td>D</td>\n",
       "      <td>296</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>Kitakan Conale</td>\n",
       "      <td>D</td>\n",
       "      <td>297</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lilace Leonzaley</td>\n",
       "      <td>G</td>\n",
       "      <td>1498</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep    Destination   Age    VIP  \\\n",
       "0        0013_01      Earth      True    TRAPPIST-1e  27.0  False   \n",
       "1        0018_01      Earth     False    TRAPPIST-1e  19.0  False   \n",
       "2        0019_01     Europa      True    55 Cancri e  31.0  False   \n",
       "3        0021_01     Europa     False    TRAPPIST-1e  38.0  False   \n",
       "4        0023_01      Earth     False    TRAPPIST-1e  20.0  False   \n",
       "...          ...        ...       ...            ...   ...    ...   \n",
       "4272     9266_02      Earth      True    TRAPPIST-1e  34.0  False   \n",
       "4273     9269_01      Earth     False    TRAPPIST-1e  42.0  False   \n",
       "4274     9271_01       Mars      True    55 Cancri e   NaN  False   \n",
       "4275     9273_01     Europa     False            NaN   NaN  False   \n",
       "4276     9277_01      Earth      True  PSO J318.5-22  43.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0   Nelly Carsoning   \n",
       "1             0.0        9.0           0.0  2823.0     0.0    Lerome Peckers   \n",
       "2             0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus   \n",
       "3             0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter   \n",
       "4            10.0        0.0         635.0     0.0     0.0   Brence Harperez   \n",
       "...           ...        ...           ...     ...     ...               ...   \n",
       "4272          0.0        0.0           0.0     0.0     0.0       Jeron Peter   \n",
       "4273          0.0      847.0          17.0    10.0   144.0     Matty Scheron   \n",
       "4274          0.0        0.0           0.0     0.0     0.0       Jayrin Pore   \n",
       "4275          0.0     2680.0           0.0     0.0   523.0    Kitakan Conale   \n",
       "4276          0.0        0.0           0.0     0.0     0.0  Lilace Leonzaley   \n",
       "\n",
       "     Deck   Num Side  \n",
       "0       G     3    S  \n",
       "1       F     4    S  \n",
       "2       C     0    S  \n",
       "3       C     1    S  \n",
       "4       F     5    S  \n",
       "...   ...   ...  ...  \n",
       "4272    G  1496    S  \n",
       "4273  NaN   NaN  NaN  \n",
       "4274    D   296    P  \n",
       "4275    D   297    P  \n",
       "4276    G  1498    S  \n",
       "\n",
       "[4277 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin = final_data['Cabin'].str.split('/', 3, expand=True)\n",
    "cabin.columns = ['Deck', 'Num', 'Side']\n",
    "final_data_mod = pd.concat([final_data, cabin], axis=1)\n",
    "final_data_mod.drop(['Cabin'], axis=1, inplace=True)\n",
    "final_data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a818743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4277"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = final_data_mod[features]\n",
    "ohe_final = pd.DataFrame(ohe.transform(ff[usecat]))\n",
    "ohe_final.index = ff.index\n",
    "\n",
    "i_X_final = pd.DataFrame(i.fit_transform(ff[numdata]))\n",
    "i_X_final.columns = ff[numdata].columns\n",
    "i_X_final.index = ff.index\n",
    "\n",
    "both_X_final = pd.concat([i_X_final, ohe_final], axis=1)\n",
    "both_X_final.columns = both_X.columns.astype(str)\n",
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c38dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = model.predict(both_X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6575049",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': final_data.PassengerId, 'Transported': final_preds})\n",
    "output.to_csv('submission6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
